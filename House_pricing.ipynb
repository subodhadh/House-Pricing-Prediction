{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b0314f9-c97e-45eb-bc46-38fae3025125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58e5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "data=fetch_california_housing()\n",
    "X=data.data\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35619f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8457897",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3982eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\my coding journey\\deep learning\\deep\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input layer + hidden layers\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output layer (regression → 1 neuron, linear activation)\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "163f329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db342fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.8188 - mae: 0.6051 - val_loss: 0.4585 - val_mae: 0.4700\n",
      "Epoch 2/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3983 - mae: 0.4487 - val_loss: 0.4078 - val_mae: 0.4546\n",
      "Epoch 3/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3711 - mae: 0.4300 - val_loss: 0.3885 - val_mae: 0.4525\n",
      "Epoch 4/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3442 - mae: 0.4155 - val_loss: 0.3641 - val_mae: 0.4283\n",
      "Epoch 5/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3321 - mae: 0.4052 - val_loss: 0.3588 - val_mae: 0.4225\n",
      "Epoch 6/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3273 - mae: 0.4001 - val_loss: 0.3524 - val_mae: 0.4220\n",
      "Epoch 7/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3848 - mae: 0.4015 - val_loss: 0.3393 - val_mae: 0.4105\n",
      "Epoch 8/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3269 - mae: 0.3913 - val_loss: 0.3328 - val_mae: 0.4022\n",
      "Epoch 9/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3044 - mae: 0.3830 - val_loss: 0.3334 - val_mae: 0.3984\n",
      "Epoch 10/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3020 - mae: 0.3811 - val_loss: 0.3280 - val_mae: 0.3995\n",
      "Epoch 11/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3013 - mae: 0.3778 - val_loss: 0.3305 - val_mae: 0.3963\n",
      "Epoch 12/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2997 - mae: 0.3768 - val_loss: 0.3228 - val_mae: 0.3925\n",
      "Epoch 13/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2887 - mae: 0.3722 - val_loss: 0.3176 - val_mae: 0.3851\n",
      "Epoch 14/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2908 - mae: 0.3701 - val_loss: 0.3201 - val_mae: 0.3851\n",
      "Epoch 15/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2879 - mae: 0.3703 - val_loss: 0.3183 - val_mae: 0.3862\n",
      "Epoch 16/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2847 - mae: 0.3678 - val_loss: 0.3140 - val_mae: 0.3891\n",
      "Epoch 17/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2841 - mae: 0.3654 - val_loss: 0.3148 - val_mae: 0.3818\n",
      "Epoch 18/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2822 - mae: 0.3640 - val_loss: 0.3127 - val_mae: 0.3787\n",
      "Epoch 19/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2774 - mae: 0.3630 - val_loss: 0.3087 - val_mae: 0.3886\n",
      "Epoch 20/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2797 - mae: 0.3605 - val_loss: 0.3077 - val_mae: 0.3783\n",
      "Epoch 21/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2727 - mae: 0.3595 - val_loss: 0.3059 - val_mae: 0.3763\n",
      "Epoch 22/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2774 - mae: 0.3584 - val_loss: 0.3387 - val_mae: 0.4193\n",
      "Epoch 23/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2720 - mae: 0.3576 - val_loss: 0.3060 - val_mae: 0.3708\n",
      "Epoch 24/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2693 - mae: 0.3561 - val_loss: 0.3130 - val_mae: 0.3708\n",
      "Epoch 25/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2681 - mae: 0.3542 - val_loss: 0.3100 - val_mae: 0.3711\n",
      "Epoch 26/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2639 - mae: 0.3518 - val_loss: 0.2969 - val_mae: 0.3736\n",
      "Epoch 27/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2645 - mae: 0.3524 - val_loss: 0.3159 - val_mae: 0.3965\n",
      "Epoch 28/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2620 - mae: 0.3509 - val_loss: 0.2982 - val_mae: 0.3699\n",
      "Epoch 29/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2611 - mae: 0.3495 - val_loss: 0.3004 - val_mae: 0.3711\n",
      "Epoch 30/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2587 - mae: 0.3480 - val_loss: 0.3021 - val_mae: 0.3859\n",
      "Epoch 31/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2589 - mae: 0.3485 - val_loss: 0.3018 - val_mae: 0.3728\n",
      "Epoch 32/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2579 - mae: 0.3464 - val_loss: 0.3160 - val_mae: 0.3993\n",
      "Epoch 33/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2577 - mae: 0.3465 - val_loss: 0.2937 - val_mae: 0.3687\n",
      "Epoch 34/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2536 - mae: 0.3446 - val_loss: 0.2895 - val_mae: 0.3620\n",
      "Epoch 35/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2562 - mae: 0.3441 - val_loss: 0.2913 - val_mae: 0.3686\n",
      "Epoch 36/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2528 - mae: 0.3435 - val_loss: 0.2962 - val_mae: 0.3669\n",
      "Epoch 37/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2533 - mae: 0.3444 - val_loss: 0.3009 - val_mae: 0.3764\n",
      "Epoch 38/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2501 - mae: 0.3417 - val_loss: 0.2976 - val_mae: 0.3740\n",
      "Epoch 39/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2503 - mae: 0.3416 - val_loss: 0.2936 - val_mae: 0.3603\n",
      "Epoch 40/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2526 - mae: 0.3434 - val_loss: 0.3074 - val_mae: 0.3688\n",
      "Epoch 41/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2495 - mae: 0.3422 - val_loss: 0.2897 - val_mae: 0.3573\n",
      "Epoch 42/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2488 - mae: 0.3397 - val_loss: 0.2919 - val_mae: 0.3716\n",
      "Epoch 43/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2482 - mae: 0.3410 - val_loss: 0.2945 - val_mae: 0.3613\n",
      "Epoch 44/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2561 - mae: 0.3423 - val_loss: 0.2908 - val_mae: 0.3643\n",
      "Epoch 45/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2487 - mae: 0.3390 - val_loss: 0.2925 - val_mae: 0.3721\n",
      "Epoch 46/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2439 - mae: 0.3370 - val_loss: 0.2947 - val_mae: 0.3745\n",
      "Epoch 47/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2442 - mae: 0.3362 - val_loss: 0.2855 - val_mae: 0.3585\n",
      "Epoch 48/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2429 - mae: 0.3365 - val_loss: 0.2990 - val_mae: 0.3680\n",
      "Epoch 49/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2441 - mae: 0.3371 - val_loss: 0.2920 - val_mae: 0.3749\n",
      "Epoch 50/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2424 - mae: 0.3367 - val_loss: 0.2939 - val_mae: 0.3595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2610c121940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f01a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2793 - mae: 0.3493\n",
      "Test MAE: 0.34931138157844543\n"
     ]
    }
   ],
   "source": [
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"Test MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d64b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Predicted House Price: $389868.00\n"
     ]
    }
   ],
   "source": [
    "# Example user input (8 features)\n",
    "user_input = np.array([[8.3252, 41, 6.9841, 1.0238,\n",
    "                        322, 2.5556, 37.88, -122.23]])\n",
    "\n",
    "user_input_scaled = scaler.transform(user_input)\n",
    "\n",
    "prediction = model.predict(user_input_scaled)\n",
    "\n",
    "print(f\"Predicted House Price: ${prediction[0][0] * 100000:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
